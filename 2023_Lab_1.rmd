---
title: "Micro-Mobility Mishap: Lab 1"
author: "Team Micro-Mobility Mishap"
output: html_document
---

##### 5a. Load your dataset into R as a dataframe. 

Check your dataframe and refer to ?read.csv to specify correct options (etc. whether column names are loaded, whether columns are correctly separated). 

We will only be using your likert-style variables (from part 3) in this exercise. You may also need to do some data cleaning once the dataset is loaded (e.g, make sure you declare any missing values for your likert-style questions!). We will not be looking at the other variables, but you might find it good practice to make sure those are read correctly, and to do some analyses in R with those variables. 
```{r}
# If you look at the Github, there's two csv files: 
# Micro-MobilityMishapMitigation_FormResponses.csv = unedited dataset
# RecodedResponses.csv = renamed titles for (much) easier coding as you'll see

df <- read.csv("RecodedResponses.csv")
```

For the rest of the exercise, we will show you how to analyze your data by using an example dataset. We will be using the bfi dataset from the psych package. You will need to install and load the psych package to run our examples below. Also, you need the psych package in order to use the "alpha" function to calculate Cronbach's alpha. 
```{r}
head(df)
str(df)
```

##### 5b. Compute the average inter-tem correlations for each item.

We will be focusing on A1-A5 of the bfi dataset, which correspond to a measure of Agreeableness. 

Step 1: Make sure your variables are numeric/integer and have missing values correctly encoded as NA. 

```{r}

# Not too sure if this is right but...
# You'll see that the variables from the dataframe are currently in char. We need to turn them into numeric/ints due to Step 1
# As a result, we need to recode the char responses into int variables
# I pulled this code from StackOverflow; might need to download car package to make this work

# Here's the car package 

#install.packages("car")
#library(car)

# Recoding char variables (responses) as numeric/integer variables

df$recoded_E = car::recode(df$E, "'I feel very unsafe'=5; 'I feel unsafe'=4; 'I feel neither unsafe nor safe'=3; 'I feel safe'=2; 'I feel very safe'=1; 'Not applicable (N/A)'=NA")

df$recoded_F = car::recode(df$F, "'I feel very unsafe'=5; 'I feel unsafe'=4; 'I feel neither unsafe nor safe'=3; 'I feel safe'=2; 'I feel very safe'=1; 'Not applicable (N/A)'=NA")

df$recoded_G = car::recode(df$G, "'Strongly disagree'=5; 'Disagree'=4; 'Neither disagree nor agree'=3; 'Agree'=2; 'Strongly agree'=1; 'Not applicable (N/A)'=NA")

df$recoded_H = car::recode(df$H, "'Strongly disagree'=5; 'Disagree'=4; 'Neither disagree nor agree'=3; 'Agree'=2; 'Strongly agree'=1; 'Not applicable (N/A)'=NA")

# Creating a new dataframe containing only those variables

scale_df = df[, c("recoded_E","recoded_F", "recoded_G", "recoded_H")]

# [Error Check] Check the class of your variables

str(scale_df)

# [Error Check] Check you have encoded the missing values correctly

str(scale_df$recoded_E)
str(scale_df$recoded_F)
str(scale_df$recoded_G)
str(scale_df$recoded_H)
```

Step 2: Flip any variables that are reverse-coded. 

If you look at the documentation for bfi carefully, you'll see that A1, unlike A2-A5, is reverse-coded. I.e. someone who answers "Very Accurate" to "Am indifferent to the feelings of others" is likely to measure low among a dimension of Agreeableness.
```{r}

# Reverse-coding A1

# The following is a quicker way to do multiple recodes using a specialized recode function. 

# You can also use the method we outline in the R tutorial and class session using indexing. 

# We need to recode Question G
# The top answer "Strongly disagree" = 6 would result in neg correlations with Question E, F, and G

scale_df$reverse_recoded_G = car::recode(scale_df$recoded_G, "1=5; 2=4; 3=3; 4=2; 5=1; NA=NA")

# [Error Check] Check the recode has been done correctly

head(scale_df[, c("recoded_G", "reverse_recoded_G")], 10)
```

Step 3: Run the correlation matrix. 

Read ?cor to make sure you understand the arguments. See under details "For cov and cor one must either give a matrix or data frame for x or give both x and y."

Notice we have selected pairwise.complete.obs, which means for each pair of variables we are correlating, we do not include rows for which either variable has an NA value. In other words, some respondents (rows) may not respond to every question (columns). This means that the number of values used to calculate correlation for each pair of variables may differ depending on the pair used. 

We do not need to supply the "method" argument for cor() as the default calculation uses Pearson's correlation coefficients, which is what we want. We will revisit correlations in more detail later in the course.  
```{r}
# Pretty much just followed what was already in Lab_1.rmd
# Diagonal 1.0 as well as no negative correlations showed me that it sorta worked, but haven't checked the nums, maybe inaccurate

scale_df2 = scale_df[, c("recoded_E", "recoded_F", "reverse_recoded_G", "recoded_H")]
cor(x=scale_df2, use = "pairwise.complete.obs")
```

Step 4: Compute the average inter-item correlation for each item.

```{r}

# No clue if I did this right lol, worth a check

# You can assign the output of the cor function to a variable 
corr_matrix = cor(x=scale_df2, use = "pairwise.complete.obs")

# [Error check] Check the class of the function output (is a matrix). 
#class(corr_matrix)

# Similar to dataframes, you can select the elements you want from the matrix, and feed it into the mean function to get your average inter-item correlation 

# Make sure you exclude the correlation of the variable with itself, as you select the elements to compute each inter-item correlation. 

recoded_E_corrs = corr_matrix[1 , c(2,3,4)]

# [Error check] Double-check to make sure you've selected the elements of each matrix correctly. 
recoded_E_corrs
#corr_matrix

# [Error check]
is.vector(recoded_E_corrs)
#class(recoded_E_corrs)

average_recoded_E_corrs = mean(recoded_E_corrs)
average_recoded_E_corrs

#-------------

recoded_F_corrs = corr_matrix[2 , c(1,3,4)]

# [Error check] Double-check to make sure you've selected the elements of each matrix correctly. 
recoded_F_corrs
#corr_matrix

# [Error check]
is.vector(recoded_F_corrs)
#class(recoded_F_corrs)

average_recoded_F_corrs = mean(recoded_F_corrs)
average_recoded_F_corrs

#-------------

recoded_G_corrs = corr_matrix[3 , c(1,2,4)]

# [Error check] Double-check to make sure you've selected the elements of each matrix correctly. 
recoded_G_corrs
#corr_matrix

# [Error check]
is.vector(recoded_G_corrs)
#class(recoded_F_corrs)

average_recoded_G_corrs = mean(recoded_G_corrs)
average_recoded_G_corrs

#-------------

recoded_H_corrs = corr_matrix[4 , c(1,2,3)]

# [Error check] Double-check to make sure you've selected the elements of each matrix correctly. 
recoded_H_corrs
#corr_matrix

# [Error check]
is.vector(recoded_H_corrs)
#class(recoded_F_corrs)

average_recoded_H_corrs = mean(recoded_H_corrs)
average_recoded_H_corrs

```

##### 5c. Answer this (and all questions/sub-questions) in your lab write-up. 

##### 5d. Calculate Cronbachâ€™s alpha for your set of likert-style variables. 

Let's say after calculating the average inter-item correlation for each variable, we decide to keep all A1-A5 variables to construct our scale.

We now want to calculate the Cronbach's alpha associated with these 5 variables. 

Looking at ?psych::alpha, you'll see that setting check.keys=TRUE will automatically reverse variables negatively correlated with the total scale. Since we already reverse-coded A1 earlier, setting this option to TRUE does not affect the output of the function. 

```{r}
#psych::alpha(scale_df2[, c("recode_A1", "A2", "A3", "A4", "A5")], check.keys=TRUE)
```

We get a (raw_alpha) value of 0.7 in the bfi data. The raw_alpha corresponds to the Cronbach's alpha definition we discussed in class. A table of definitions for the output can be viewed at the end of ?psych::alpha. 

##### 5e.	Create a new scale which is the average of your likert-style variables. 

When we decide that several items should be part of the same scale, the last step is to actually create a new variable that averages those items together. 

We want you to create a new scale which is the average of your likert-style variables. You should have already declared your missing values and reverse-coded any necessary variables (eg, if you have a scale of "happiness" but one of your questions is, "In general I am not happy", you would reverse-code that item so that higher values = higher happiness). 

Important: In calculating our row mean below, please note that we are choosing not to remove the NA cases entirely-- thus, we will calculate the non-missing mean. So, if someone answers only 4 questions, we get the average of 4 answered questions, if they answer only 3, we only get the average of those 3 questions, and so on. There are other ways to handle missing data too, which we will discuss in an upcoming lecture.
```{r}
#library(car)
# Get the row mean of A1-A5. 
# The column index argument is unnecessary (since scale_df2 only has those 5 columns) but included for clarity. 
#scale_df2$scale = rowMeans(scale_df2[, c("recode_A1", "A2", "A3", "A4", "A5")], na.rm=TRUE)

# [Error check] Make sure the function does as expected - checking rows with NA values in particular. 
#tail(scale_df2, 50)
```

##### 5f. Plot a histogram for each of your likert-style variables, and a histogram for your new scale (the average of your likert-style variables). Include these histograms in your lab pdf write-up, and briefly discuss and interpret any notable differences between the individual histograms and the histogram of your new scale.  

```{r}
#hist(scale_df2$recode_A1)
#hist(scale_df2$A2)
#hist(scale_df2$A3)
#hist(scale_df2$A4)
#hist(scale_df2$A5)

# Increasing the number of breaks allows you to see more of the granularity in your new scale variable.  
#hist(scale_df2$scale, breaks=24)
```